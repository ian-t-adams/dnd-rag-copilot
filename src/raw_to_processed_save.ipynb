{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by Step Guide to a Dungeons and Dragons (DnD) Retrieval Augmented Generation (RAG) Copilot\n",
    "\n",
    "## Set-up\n",
    "\n",
    "### Import necessary Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Necessary Python Libraries\n",
    "\n",
    "# Import standard and non-Azure libraries\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import the Azure SDK libraries\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Import the custom functions\n",
    "import functions as fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables from .env and configuration variables from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # populate environment variables from .env file\n",
    "\n",
    "# Open the config.json file and read the configurations\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "openai_api_key: str = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai_api_base: str = os.environ[\"OPENAI_API_BASE\"]\n",
    "vector_store_address: str = os.environ['SEARCH_ENDPOINT']\n",
    "vector_store_password: str = os.environ['SEARCH_KEY']\n",
    "document_intelligence_endpoint: str = os.environ[\"DOCUMENT_INTELLIGENCE_ENDPOINT\"]\n",
    "document_intelligence_key: str = os.environ[\"DOCUMENT_INTELLIGENCE_KEY\"]\n",
    "storage_account_url: str = os.environ[\"STORAGE_ACCOUNT_URL\"]\n",
    "blob_raw_sas_token: str = os.environ[\"BLOB_RAW_SAS_TOKEN\"]\n",
    "blob_processed_sas_token: str = os.environ[\"BLOB_PROCESSED_SAS_TOKEN\"]\n",
    "blob_final_sas_token: str = os.environ[\"BLOB_FINAL_SAS_TOKEN\"]\n",
    "\n",
    "# Load configs from config.json file\n",
    "openai_api_type: str = config[\"AOAI_CONFIGS\"][\"API_TYPE\"] # \"azure\"\n",
    "openai_api_version: str = config[\"AOAI_CONFIGS\"][\"API_VERSION\"] # = \"2023-08-01-preview\"\n",
    "doc_intel_model: str = config[\"DOC_INTEL_CONFIGS\"][\"ANALYSIS_MODEL\"] # = \"prebuilt-layout\"\n",
    "raw_container_name: str = config[\"BLOB_STORAGE_CONFIGS\"][\"RAW_CONTAINER\"] # = \"dnd-rag-bot-raw\"\n",
    "processed_container_name: str = config[\"BLOB_STORAGE_CONFIGS\"][\"PROCESSED_CONTAINER\"] # = \"dnd-rag-bot-processed\"\n",
    "final_container_name: str = config[\"BLOB_STORAGE_CONFIGS\"][\"FINAL_CONTAINER\"] # = \"dnd-rag-bot-final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the documents from Raw, process with Document Intelligence, and write to Processed\n",
    "\n",
    "### Create the BlobServiceClients for the storage containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://pypi.org/project/azure-identity/\n",
    "# We are using a blob SAS url + token, but you could define at the overall blob and not container or use default credentials \n",
    "# token + url allows us to set expirations for access\n",
    "\n",
    "# Create the BlobServiceClient object so we can connect to the blob storage\n",
    "# One for raw documents, one for processed documents, and one for the final chunked data before it goes into the search index \n",
    "raw_blob_service_client = BlobServiceClient(storage_account_url, blob_raw_sas_token)\n",
    "processed_blob_service_client = BlobServiceClient(storage_account_url, blob_processed_sas_token)\n",
    "final_blob_service_client = BlobServiceClient(storage_account_url, blob_final_sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the urls for the document in the Raw Container and Extract Blob URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dictionary of blob names and urls for each container\n",
    "dictionary_of_raw_blobs = fn.blob_name_and_url_dict(raw_blob_service_client, raw_container_name)\n",
    "print(dictionary_of_raw_blobs)\n",
    "\n",
    "# Specify the container name, file extension, and file name\n",
    "# We are selecting based on the raw container and the .pdf file extension\n",
    "# as we know specifically which file we are after.\n",
    "# Use the raw_container_name from configs.json\n",
    "file_extension = '.pdf'\n",
    "dnd_pdf_name = 'DnD 5e Players Handbook (BnW OCR).pdf'\n",
    "\n",
    "# Access the URL\n",
    "dnd_pdf_url = dictionary_of_raw_blobs[raw_container_name][file_extension][dnd_pdf_name]['blob_url']\n",
    "# print(dnd_pdf_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the pdf into the DocumentAnalysisClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DocumentAnalysisClient object so we can connect to the document intelligence service and read in the document\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "                endpoint=document_intelligence_endpoint, credential=AzureKeyCredential(document_intelligence_key)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the doc_intel_pdf function and choose which model to use, in this case we are using the prebuilt-layout model\n",
    "# The function will return the result, the dictionary of results, or both depending on the last parameter\n",
    "# We are supplying the file name and the url is being extracted from the dictionary of blobs\n",
    "\n",
    "dnd_pdf_doc_intel_result, dnd_pdf_doc_intel_dict = fn.doc_intel_pdf(document_analysis_client, doc_intel_model, dnd_pdf_name, dnd_pdf_url, 'both')\n",
    "# print(dnd_pdf_doc_intel_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Write to / Read From local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the local_file_write function to write the results to a local file\n",
    "# # We are writing the results to a text file and the dictionary to a json file\n",
    "# fn.local_file_write(dnd_pdf_doc_intel_result, 'text', '../data/results/raw_results', 'dnd_pdf_doc_intel_result.txt')\n",
    "# fn.local_file_write(dnd_pdf_doc_intel_dict, 'json', '../data/results/dictionaries', 'dnd_pdf_doc_intel_dict.json')\n",
    "\n",
    "# # Or read in the results from local to save time / doc intel costs\n",
    "# dnd_pdf_doc_intel_result_test = fn.local_file_read('../data/results/raw_results/dnd_pdf_doc_intel_result.txt', 'text')\n",
    "# dnd_pdf_doc_intel_dict_test = fn.local_file_read('../data/results/dictionaries/dnd_pdf_doc_intel_dict.json', 'json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to the Processed Blob Storage\n",
    "This saves the output from Document Intelligence so we don't have to\n",
    "recreate that object every time we want to iterate over the\n",
    "OCR output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the results to the processed container\n",
    "fn.write_to_blob(dnd_pdf_doc_intel_result, processed_blob_service_client, processed_container_name, 'raw_results', 'dnd_pdf_doc_intel_result.txt', False)\n",
    "fn.write_to_blob(dnd_pdf_doc_intel_dict, processed_blob_service_client, processed_container_name, 'dictionaries', 'dnd_pdf_doc_intel_dict.json', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in from Processed Blob Storage\n",
    "This allows for these processes to live in separate Function Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_of_processed_blobs = fn.blob_name_and_url_dict(processed_blob_service_client, processed_container_name)\n",
    "# print(dictionary_of_processed_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be working pimarily with the dictionary of processed blobs, so we will load that in\n",
    "# and using the json dictionary representation of the Document Ingeligence results\n",
    "dnd_pdf_doc_intel_dict = fn.load_blob(dictionary_of_processed_blobs, container_name='dnd-rag-bot-processed', file_type='.json', file_name='dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json')\n",
    "\n",
    "# dnd_pdf_doc_intel_result = fn.load_blob(dictionary_of_processed_blobs, container_name='dnd-rag-bot-processed', file_type='.txt', file_name='dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnd-rag-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
