{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by Step Guide to a Dungeons and Dragons (DnD) Retrieval Augmented Generation (RAG) Copilot\n",
    "\n",
    "## Set-up\n",
    "\n",
    "### Import necessary Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Necessary Python Libraries\n",
    "\n",
    "# Import standard and non-Azure libraries\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import the Azure SDK libraries\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import AzureError\n",
    "\n",
    "# Import the custom functions\n",
    "import functions as fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables from .env and configuration variables from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # populate environment variables from .env file\n",
    "\n",
    "# Open the config.json file and read the configurations\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "openai_api_key: str = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai_api_base: str = os.environ[\"OPENAI_API_BASE\"]\n",
    "vector_store_address: str = os.environ['SEARCH_ENDPOINT']\n",
    "vector_store_password: str = os.environ['SEARCH_KEY']\n",
    "document_intelligence_endpoint: str = os.environ[\"DOCUMENT_INTELLIGENCE_ENDPOINT\"]\n",
    "document_intelligence_key: str = os.environ[\"DOCUMENT_INTELLIGENCE_KEY\"]\n",
    "storage_account_url: str = os.environ[\"STORAGE_ACCOUNT_URL\"]\n",
    "blob_raw_sas_token: str = os.environ[\"BLOB_RAW_SAS_TOKEN\"]\n",
    "blob_processed_sas_token: str = os.environ[\"BLOB_PROCESSED_SAS_TOKEN\"]\n",
    "blob_final_sas_token: str = os.environ[\"BLOB_FINAL_SAS_TOKEN\"]\n",
    "\n",
    "# Load configs from config.json file\n",
    "openai_api_type: str = config[\"AOAI_CONFIGS\"][\"API_TYPE\"] # \"azure\"\n",
    "openai_api_version: str = config[\"AOAI_CONFIGS\"][\"API_VERSION\"] # = \"2023-08-01-preview\"\n",
    "doc_intel_model: str = config[\"DOC_INTEL_CONFIGS\"][\"ANALYSIS_MODEL\"] # = \"prebuilt-layout\"\n",
    "raw_container_name: str = config[\"BLOB_STORAGE_CONFIGS\"][\"RAW_CONTAINER\"] # = \"dnd-rag-bot-raw\"\n",
    "processed_container_name: str = config[\"BLOB_STORAGE_CONFIGS\"][\"PROCESSED_CONTAINER\"] # = \"dnd-rag-bot-processed\"\n",
    "final_container_name: str = config[\"BLOB_STORAGE_CONFIGS\"][\"FINAL_CONTAINER\"] # = \"dnd-rag-bot-final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the documents from Raw, process with Document Intelligence, and write to Processed\n",
    "\n",
    "### Create the BlobServiceClients for the storage containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://pypi.org/project/azure-identity/\n",
    "# We are using a blob SAS url + token, but you could define at the overall blob and not container or use default credentials \n",
    "# token + url allows us to set expirations for access\n",
    "\n",
    "# Create the BlobServiceClient object so we can connect to the blob storage\n",
    "# One for raw documents, one for processed documents, and one for the final chunked data before it goes into the search index \n",
    "raw_blob_service_client = BlobServiceClient(storage_account_url, blob_raw_sas_token)\n",
    "processed_blob_service_client = BlobServiceClient(storage_account_url, blob_processed_sas_token)\n",
    "final_blob_service_client = BlobServiceClient(storage_account_url, blob_final_sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the urls for the document in the Raw Container and Extract Blob URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dictionary of blob names and urls for each container\n",
    "dictionary_of_raw_blobs = fn.blob_name_and_url_dict(raw_blob_service_client, raw_container_name)\n",
    "print(dictionary_of_raw_blobs)\n",
    "\n",
    "# Specify the container name, file extension, and file name\n",
    "# We are selecting based on the raw container and the .pdf file extension\n",
    "# as we know specifically which file we are after.\n",
    "# Use the raw_container_name from configs.json\n",
    "file_extension = '.pdf'\n",
    "dnd_pdf_name = 'DnD 5e Players Handbook (BnW OCR).pdf'\n",
    "\n",
    "# Access the URL\n",
    "dnd_pdf_url = dictionary_of_raw_blobs[raw_container_name][file_extension][dnd_pdf_name]['blob_url']\n",
    "# print(dnd_pdf_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the pdf into the DocumentAnalysisClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DocumentAnalysisClient object so we can connect to the document intelligence service and read in the document\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "                endpoint=document_intelligence_endpoint, credential=AzureKeyCredential(document_intelligence_key)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the doc_intel_pdf function and choose which model to use, in this case we are using the prebuilt-layout model\n",
    "# The function will return the result, the dictionary of results, or both depending on the last parameter\n",
    "# We are supplying the file name and the url is being extracted from the dictionary of blobs\n",
    "\n",
    "dnd_pdf_doc_intel_result, dnd_pdf_doc_intel_dict = fn.doc_intel_pdf(document_analysis_client, doc_intel_model, dnd_pdf_name, dnd_pdf_url, 'both')\n",
    "# print(dnd_pdf_doc_intel_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Write to / Read From local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the local_file_write function to write the results to a local file\n",
    "# # We are writing the results to a text file and the dictionary to a json file\n",
    "# fn.local_file_write(dnd_pdf_doc_intel_result, 'text', '../data/results/raw_results', 'dnd_pdf_doc_intel_result.txt')\n",
    "# fn.local_file_write(dnd_pdf_doc_intel_dict, 'json', '../data/results/dictionaries', 'dnd_pdf_doc_intel_dict.json')\n",
    "\n",
    "# # Or read in the results from local to save time / doc intel costs\n",
    "# dnd_pdf_doc_intel_result_test = fn.local_file_read('../data/results/raw_results/dnd_pdf_doc_intel_result.txt', 'text')\n",
    "# dnd_pdf_doc_intel_dict_test = fn.local_file_read('../data/results/dictionaries/dnd_pdf_doc_intel_dict.json', 'json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to the Processed Blob Storage\n",
    "This saves the output from Document Intelligence so we don't have to\n",
    "recreate that object every time we want to iterate over the\n",
    "OCR output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the results to the processed container\n",
    "fn.write_to_blob(dnd_pdf_doc_intel_result, processed_blob_service_client, processed_container_name, 'raw_results', 'dnd_pdf_doc_intel_result.txt', False)\n",
    "fn.write_to_blob(dnd_pdf_doc_intel_dict, processed_blob_service_client, processed_container_name, 'dictionaries', 'dnd_pdf_doc_intel_dict.json', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in from Processed Blob Storage\n",
    "This allows for these processes to live in separate Function Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The container dnd-rag-bot-processed is being accessed.\n",
      "The file dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json located at https://iancogsearchstorage.blob.core.windows.net/dnd-rag-bot-processed/dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json?si=dnd-rag-bot&spr=https&sv=2022-11-02&sr=c&sig=R6J8EuDEVTvG41nmQ1QlSDexuRT2%2BqDNv0yBiJc0kvc%3D is being added to the blob list.\n",
      "The file dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt located at https://iancogsearchstorage.blob.core.windows.net/dnd-rag-bot-processed/dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt?si=dnd-rag-bot&spr=https&sv=2022-11-02&sr=c&sig=R6J8EuDEVTvG41nmQ1QlSDexuRT2%2BqDNv0yBiJc0kvc%3D is being added to the blob list.\n",
      "{'dnd-rag-bot-processed': {'.json': {'dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json': {'file_name': 'dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json', 'blob_url': 'https://iancogsearchstorage.blob.core.windows.net/dnd-rag-bot-processed/dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json?si=dnd-rag-bot&spr=https&sv=2022-11-02&sr=c&sig=R6J8EuDEVTvG41nmQ1QlSDexuRT2%2BqDNv0yBiJc0kvc%3D'}}, '.txt': {'dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt': {'file_name': 'dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt', 'blob_url': 'https://iancogsearchstorage.blob.core.windows.net/dnd-rag-bot-processed/dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt?si=dnd-rag-bot&spr=https&sv=2022-11-02&sr=c&sig=R6J8EuDEVTvG41nmQ1QlSDexuRT2%2BqDNv0yBiJc0kvc%3D'}}}}\n"
     ]
    }
   ],
   "source": [
    "dictionary_of_processed_blobs = fn.blob_name_and_url_dict(processed_blob_service_client, processed_container_name)\n",
    "print(dictionary_of_processed_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_blob(blob_dict, file_type=None, file_name=None):\n",
    "    \"\"\"\n",
    "    Load a single blob from a nested dictionary of blob names and URLs.\n",
    "\n",
    "    Parameters:\n",
    "    blob_dict (dict): A nested dictionary where keys are container names, file types, and blob names, and values are blob details.\n",
    "    file_type (str, optional): The file type to filter blobs by. Blobs not of this file type will be ignored.\n",
    "    file_name (str, optional): A specific blob name to load. If provided, only this blob will be loaded.\n",
    "\n",
    "    Returns:\n",
    "    bytes: The content of the blob.\n",
    "\n",
    "    Example usage:\n",
    "    blob_dict = {\"container1\": {\".txt\": {\"blob1\": {\"file_name\": \"blob1\", \"blob_url\": \"url1\"}}}}\n",
    "    load_blob(blob_dict, file_type=\".txt\", file_name=\"blob1\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over all containers in the dictionary\n",
    "    for container_name, container_dict in blob_dict.items():\n",
    "        # If file_type is provided and it does not exist in the current container's dictionary, skip this container\n",
    "        if file_type and file_type not in container_dict:\n",
    "            continue\n",
    "        # If file_type is provided, iterate over all blobs in the file_type dictionary, otherwise in the container's dictionary\n",
    "        for blob_name, blob_details in (container_dict[file_type] if file_type else container_dict).items():\n",
    "            # If file_name is provided and blob_name is not equal to it, skip this blob\n",
    "            if file_name and blob_name != file_name:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Create a BlobClient for the blob\n",
    "                blob_client = BlobClient.from_blob_url(blob_details['blob_url'])\n",
    "                # Download the blob and read all its content\n",
    "                blob_content = blob_client.download_blob().readall()\n",
    "\n",
    "                # Return the blob content\n",
    "                return blob_content\n",
    "            except AzureError as e:\n",
    "                print(f\"Failed to download blob: {e}\")\n",
    "                return None\n",
    "\n",
    "    # If no blob was found that matches the criteria, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking blob: dnd-rag-bot-processed at {'.json': {'dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json': {'file_name': 'dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json', 'blob_url': 'https://iancogsearchstorage.blob.core.windows.net/dnd-rag-bot-processed/dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json?si=dnd-rag-bot&spr=https&sv=2022-11-02&sr=c&sig=R6J8EuDEVTvG41nmQ1QlSDexuRT2%2BqDNv0yBiJc0kvc%3D'}}, '.txt': {'dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt': {'file_name': 'dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt', 'blob_url': 'https://iancogsearchstorage.blob.core.windows.net/dnd-rag-bot-processed/dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt?si=dnd-rag-bot&spr=https&sv=2022-11-02&sr=c&sig=R6J8EuDEVTvG41nmQ1QlSDexuRT2%2BqDNv0yBiJc0kvc%3D'}}}\n",
      "Checking blob: dnd-rag-bot-processed at {'.json': {'dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json': {'file_name': 'dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json', 'blob_url': 'https://iancogsearchstorage.blob.core.windows.net/dnd-rag-bot-processed/dnd-rag-bot-processed/dictionaries/dnd_pdf_doc_intel_dict.json?si=dnd-rag-bot&spr=https&sv=2022-11-02&sr=c&sig=R6J8EuDEVTvG41nmQ1QlSDexuRT2%2BqDNv0yBiJc0kvc%3D'}}, '.txt': {'dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt': {'file_name': 'dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt', 'blob_url': 'https://iancogsearchstorage.blob.core.windows.net/dnd-rag-bot-processed/dnd-rag-bot-processed/raw_results/dnd_pdf_doc_intel_result.txt?si=dnd-rag-bot&spr=https&sv=2022-11-02&sr=c&sig=R6J8EuDEVTvG41nmQ1QlSDexuRT2%2BqDNv0yBiJc0kvc%3D'}}}\n"
     ]
    }
   ],
   "source": [
    "dnd_pdf_doc_intel_result = load_blob(dictionary_of_processed_blobs, file_type='.txt', file_name='dnd_pdf_doc_intel_result.txt')\n",
    "dnd_pdf_doc_intel_dict = load_blob(dictionary_of_processed_blobs, file_type='.json', file_name='dnd_pdf_doc_intel_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dnd_pdf_doc_intel_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnd-rag-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
